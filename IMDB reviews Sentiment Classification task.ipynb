{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:14.565885Z",
     "start_time": "2018-08-28T04:21:10.580909Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:14.761430Z",
     "start_time": "2018-08-28T04:21:14.567894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README      imdb.vocab  imdbEr.txt  \u001b[1m\u001b[36mtest\u001b[m\u001b[m/       \u001b[1m\u001b[36mtrain\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='aclImdb/'\n",
    "TRN_PATH = 'train/all/'\n",
    "VAL_PATH = 'test/all/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:15.410961Z",
     "start_time": "2018-08-28T04:21:14.765394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_0.txt',\n",
       " '0_3.txt',\n",
       " '0_9.txt',\n",
       " '10000_0.txt',\n",
       " '10000_4.txt',\n",
       " '10000_8.txt',\n",
       " '10001_0.txt',\n",
       " '10001_10.txt',\n",
       " '10001_4.txt',\n",
       " '10002_0.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_files =  !ls {TRN}\n",
    "trn_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:15.487500Z",
     "start_time": "2018-08-28T04:21:15.413399Z"
    }
   },
   "outputs": [],
   "source": [
    "review = !cat {TRN}{trn_files[5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:15.554835Z",
     "start_time": "2018-08-28T04:21:15.490879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:26.427073Z",
     "start_time": "2018-08-28T04:21:15.557066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17491822\r\n"
     ]
    }
   ],
   "source": [
    "# Now we'll check how many words are in the dataset: Train\n",
    "!find {TRN} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:30.201362Z",
     "start_time": "2018-08-28T04:21:26.430067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5688356\r\n"
     ]
    }
   ],
   "source": [
    "# Now we'll check how many words are in the dataset: Validation\n",
    "!find {VAL} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:31.025223Z",
     "start_time": "2018-08-28T04:21:30.204578Z"
    }
   },
   "outputs": [],
   "source": [
    "#Before we can analyze text, we must first tokenize it. This refers to the process of splitting a sentence into an array of words (or more generally, into an array of tokens).\n",
    "spacy_tok = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:31.171204Z",
     "start_time": "2018-08-28T04:21:31.027505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Homelessness ( or Houselessness as George Carlin stated ) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school , work , or vote for the matter . Most people think of the homeless as just a lost cause while worrying about things such as racism , the war on Iraq , pressuring kids to succeed , technology , the elections , inflation , or worrying if they \\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home , the entertainment sets , a bathroom , pictures on the wall , a computer , and everything you once treasure to see what it \\'s like to be homeless ? That is Goddard Bolt \\'s lesson.<br /><br />Mel Brooks ( who directs ) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival ( Jeffery Tambor ) to see if he can live in the streets for thirty days without the luxuries ; if Bolt succeeds , he can do what he wants with a future project of making more buildings . The bet \\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he ca n\\'t step off the sidewalk . He \\'s given the nickname Pepto by a vagrant after it \\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly ( Lesley Ann Warren ) an ex - dancer who got divorce before losing her home , and her pals Sailor ( Howard Morris ) and Fumes ( Teddy Wilson ) who are already used to the streets . They \\'re survivors . Bolt is n\\'t . He \\'s not used to reaching mutual agreements like he once did when being rich where it \\'s fight or flight , kill or be killed.<br /><br />While the love connection between Molly and Bolt was n\\'t necessary to plot , I found \" Life Stinks \" to be one of Mel Brooks \\' observant films where prior to being a comedy , it shows a tender side compared to his slapstick work such as Blazing Saddles , Young Frankenstein , or Spaceballs for the matter , to show what it \\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they do n\\'t know what to do with their money . Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting a sentence into an array of words (or more generally, into an array of tokens).\n",
    "' '.join([sent.string.strip() for sent in spacy_tok(review[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:31.696054Z",
     "start_time": "2018-08-28T04:21:31.172994Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=\"spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:31.746008Z",
     "start_time": "2018-08-28T04:21:31.697849Z"
    }
   },
   "outputs": [],
   "source": [
    "bs=64; bptt=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:21:31.796957Z",
     "start_time": "2018-08-28T04:21:31.747705Z"
    }
   },
   "outputs": [],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T04:31:57.974697Z",
     "start_time": "2018-08-28T04:21:31.798873Z"
    }
   },
   "outputs": [],
   "source": [
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:09:28.726746Z",
     "start_time": "2018-08-28T07:09:18.545614Z"
    }
   },
   "outputs": [],
   "source": [
    "# python's standard Pickle library can't handle this correctly, so at the top of this notebook we used the dill library instead and imported it as pickle \n",
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pk1','wb'))   #Create folder models if it is not already existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:11:49.339868Z",
     "start_time": "2018-08-28T07:11:49.218121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4583, 37392, 1, 20540756)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:17:56.021670Z",
     "start_time": "2018-08-28T07:17:55.960202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " 'the',\n",
       " ',',\n",
       " '.',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'in',\n",
       " 'it',\n",
       " 'i',\n",
       " 'this']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:14]  # 'itos': int-to-String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:19:58.038197Z",
     "start_time": "2018-08-28T07:19:57.980240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['this'] # 'stoi': 'string to int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:31:00.476996Z",
     "start_time": "2018-08-28T07:31:00.419555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'that',\n",
       " 'gets',\n",
       " 'no',\n",
       " 'respect',\n",
       " 'there',\n",
       " 'sure',\n",
       " 'are',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'memorable',\n",
       " 'quotes',\n",
       " 'listed',\n",
       " 'for',\n",
       " 'this',\n",
       " 'gem',\n",
       " '.',\n",
       " 'imagine',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'where',\n",
       " 'joe',\n",
       " 'piscopo',\n",
       " 'is',\n",
       " 'actually',\n",
       " 'funny',\n",
       " '!',\n",
       " 'maureen',\n",
       " 'stapleton',\n",
       " 'is',\n",
       " 'a',\n",
       " 'scene',\n",
       " 'stealer']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:36] # Note that in a LanguageModelData object there is only one item in each dataset: all the words of the text joined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:46:38.381837Z",
     "start_time": "2018-08-28T07:46:38.254320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   22\n",
       "    6\n",
       "   23\n",
       "   14\n",
       "  234\n",
       "   69\n",
       " 1189\n",
       "   50\n",
       "  271\n",
       "   32\n",
       "    6\n",
       "  187\n",
       "[torch.LongTensor of size 12x1]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.numericalize([md.trn_ds[0].text[:12]], device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `LanguageModelData` object will create batches with 64 columns (that's our batch size), and varying sequence lengths of around 80 tokens (that's our `bptt` parameter - *backprop through time*).\n",
    "\n",
    "Each batch also contains the exact same data as labels, but one word later in the text - since we're trying to always predict the next word. The labels are flattened into a 1d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:53:10.702718Z",
     "start_time": "2018-08-28T07:53:10.573815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     22     11     52  ...   14672      9      4\n",
       "      6  18388   2087  ...      14   1048   3809\n",
       "     23     18      2  ...     107      3    766\n",
       "         ...            ⋱           ...         \n",
       "    330     27    378  ...      54     65      7\n",
       "      7     10   2952  ...       2    246     49\n",
       "    263     74   2860  ...     119   4789   1445\n",
       " [torch.LongTensor of size 77x64], Variable containing:\n",
       "      6\n",
       "  18388\n",
       "   2087\n",
       "   ⋮   \n",
       "     10\n",
       "      4\n",
       "      4\n",
       " [torch.LongTensor of size 4928])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T07:57:50.364114Z",
     "start_time": "2018-08-28T07:57:50.240550Z"
    }
   },
   "outputs": [],
   "source": [
    "em_sz = 200  # Size of each embedding vector\n",
    "nh = 500     # Number of hidden activations per layer\n",
    "nl = 3       # Number of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Researchers have found that large amounts of momentum (which we'll learn about later) don't work well with these kinds of RNN models, so we create a version of the Adam optimizer with less momentum than it's default of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T08:07:19.019370Z",
     "start_time": "2018-08-28T08:07:18.900690Z"
    }
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7,0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T08:12:57.291795Z",
     "start_time": "2018-08-28T08:12:56.779753Z"
    }
   },
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T08:14:05.143984Z",
     "start_time": "2018-08-28T08:14:05.085914Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.reg_fn = partial(seq2seq_reg,alpha=2,beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T08:14:17.565084Z",
     "start_time": "2018-08-28T08:14:17.514710Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T22:16:30.421095Z",
     "start_time": "2018-08-29T12:24:25.922417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e2ebddd4794c4f8126b75a14aa2f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      4.585941   4.466092  \n",
      "    1      4.498523   4.379587                                    \n",
      "    2      4.403773   4.34741                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.34741])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)\n",
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T02:25:53.958536Z",
     "start_time": "2018-08-31T02:25:53.613427Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('encoder1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T02:26:02.686531Z",
     "start_time": "2018-08-31T02:26:02.552762Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.load_encoder('encoder1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling accuracy is generally measured using the metric perplexity, which is simply exp() of the loss function we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T02:31:50.910135Z",
     "start_time": "2018-08-31T02:31:50.787012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.2772805720471"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(4.3474)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T02:35:08.800495Z",
     "start_time": "2018-08-31T02:35:00.632561Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pk1','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our language model and getting prediction for next words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T02:45:09.361609Z",
     "start_time": "2018-08-31T02:45:09.304428Z"
    }
   },
   "outputs": [],
   "source": [
    "lm = learner.model\n",
    "sentence =\"\"\". So, it wasn't quite i was expecting, but i really\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:01:19.856106Z",
     "start_time": "2018-08-31T03:01:19.797680Z"
    }
   },
   "outputs": [],
   "source": [
    "#tok = [spacy_tok(sentence)] commented as this was giving error\n",
    "tok = [TEXT.preprocess(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:01:21.016729Z",
     "start_time": "2018-08-31T03:01:20.955582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.',\n",
       "  'so',\n",
       "  ',',\n",
       "  'it',\n",
       "  'was',\n",
       "  \"n't\",\n",
       "  'quite',\n",
       "  'i',\n",
       "  'was',\n",
       "  'expecting',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'really']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view how token look \n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:01:29.461938Z",
     "start_time": "2018-08-31T03:01:29.403098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    4\n",
       "   48\n",
       "    3\n",
       "   11\n",
       "   19\n",
       "   29\n",
       "  198\n",
       "   12\n",
       "   19\n",
       " 1043\n",
       "    3\n",
       "   24\n",
       "   12\n",
       "   78\n",
       "[torch.LongTensor of size 14x1]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Numericalize tokens\n",
    "t = TEXT.numericalize(tok, device=-1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:01:39.033103Z",
     "start_time": "2018-08-31T03:01:38.977523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\". so , it was n't quite i was expecting , but i really\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tok[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:19:31.180585Z",
     "start_time": "2018-08-31T03:19:31.106707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "lm[0].bs=1\n",
    "# Turn off dropout\n",
    "lm.eval()\n",
    "# Reset hidden state\n",
    "lm.reset()\n",
    "# Get predections from model\n",
    "res,*_ = lm(t)\n",
    "# put batch size back to what it was\n",
    "lm[0].bs = bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at top 10 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:19:33.749946Z",
     "start_time": "2018-08-31T03:19:33.691209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did',\n",
       " 'do',\n",
       " 'wanted',\n",
       " 'enjoyed',\n",
       " 'liked',\n",
       " 'thought',\n",
       " 'felt',\n",
       " 'ca',\n",
       " 'could',\n",
       " 'was']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_10 = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(next_10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating next set of texts from model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:19:36.678938Z",
     "start_time": "2018-08-31T03:19:36.624190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". So, it wasn't quite i was expecting, but i really \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sentence,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:19:41.861359Z",
     "start_time": "2018-08-31T03:19:41.541986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did n't have the same idea . the movie was a bit of a surprise , but it was n't . it was a very good movie , but it was n't . it was a very good movie , but it was n't . <eos> i saw this movie ...\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    n = res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = lm(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:40:39.761053Z",
     "start_time": "2018-08-31T03:40:38.263340Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pk1','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sequential=False` tells torchtext that a text field should be tokenized (in this case, we just want to store the 'positive' or 'negative' single label).\n",
    "\n",
    "`splits` is a torchtext method that creates train, test, and validation sets. The IMDB dataset is built into torchtext, so we can take advantage of that. Take a look at `lang_model-arxiv.ipynb` to see how to define your own fastai/torchtext datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T03:55:24.655779Z",
     "start_time": "2018-08-31T03:49:00.428208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "IMDB_LABEL = data.Field(sequential=False)\n",
    "splits = torchtext.datasets.IMDB.splits(TEXT, IMDB_LABEL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:07:00.409050Z",
     "start_time": "2018-08-31T08:07:00.022307Z"
    }
   },
   "outputs": [],
   "source": [
    "t = splits[0].examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:07:01.155807Z",
     "start_time": "2018-08-31T08:07:01.065010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos',\n",
       " 'for a movie that gets no respect there sure are a lot of memorable quotes listed')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.label, ' '.join(t.text[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:08:46.780922Z",
     "start_time": "2018-08-31T08:08:45.978087Z"
    }
   },
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:16:58.505156Z",
     "start_time": "2018-08-31T08:16:57.890798Z"
    }
   },
   "outputs": [],
   "source": [
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:18:09.752167Z",
     "start_time": "2018-08-31T08:18:09.694103Z"
    }
   },
   "outputs": [],
   "source": [
    "m3.reg_fn = partial(seq2seq_reg, alpha=2,beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:25:26.157846Z",
     "start_time": "2018-08-31T08:25:25.931921Z"
    }
   },
   "outputs": [],
   "source": [
    "m3.load_encoder(f'encoder1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're fine-tuning a pretrained model, we'll use differential learning rates, and also increase the max gradient for clipping, to allow the SGDR to work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:26:08.083033Z",
     "start_time": "2018-08-31T08:26:08.023247Z"
    }
   },
   "outputs": [],
   "source": [
    "m3.clip=25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:26:34.959982Z",
     "start_time": "2018-08-31T08:26:34.900040Z"
    }
   },
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T08:27:00.419007Z",
     "start_time": "2018-08-31T08:27:00.356081Z"
    }
   },
   "outputs": [],
   "source": [
    "m3.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T09:33:04.772476Z",
     "start_time": "2018-08-31T08:27:34.305147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0efc4158ae4e00834e5b79cb34a824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.652715   0.413435   0.823359  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.41343]), 0.8233593852821178]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs/2,1,metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T09:33:05.001549Z",
     "start_time": "2018-08-31T09:33:04.777345Z"
    }
   },
   "outputs": [],
   "source": [
    "m3.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T17:24:34.931507Z",
     "start_time": "2018-08-31T09:33:05.003554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198667aa43ee437ab372b10bb0a9e29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                        \n",
      "    0      0.486202   0.363499   0.848203  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.3635]), 0.848202744561641]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-31T17:41:55.773126Z",
     "start_time": "2018-08-31T17:29:52.475375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85552"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np(*m3.predict_with_targs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now ready to predict the sentiment of given text/or review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
